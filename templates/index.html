<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KIST ìˆœì°°ë¡œë´‡ê³¼ ëŒ€í™”í•˜ê¸°</title>
    <style>
        body { font-family: Arial, sans-serif; }
        .chat-container { width: 50%; margin: 0 auto; }
        .messages { border: 1px solid #ccc; height: 300px; overflow-y: scroll; padding: 10px; }
        .input-group { margin-top: 10px; }
        .emotion-display { margin-top: 10px; font-size: 1.2em; color: blue; }
        .mic-visualizer {
            margin-top: 10px;
            width: 100%;
            height: 20px;
            background-color: #ddd;
            position: relative;
            overflow: hidden;
        }
        .mic-visualizer-bar {
            height: 100%;
            background-color: #007bff;
            width: 0;
            transition: width 0.1s ease-out;
        }
        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        button { padding: 10px; margin-right: 5px; cursor: pointer; border: none; background-color: #eee; }
        /* ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ(active) ìŠ¤íƒ€ì¼ */
        button.active { background-color: #007bff; color: white; transform: translateY(2px); }
    </style>
</head>
<body>
    <div class="chat-container">
        <h2>KIST ìˆœì°°ë¡œë´‡ê³¼ ëŒ€í™”í•˜ê¸°</h2>
        <div class="messages" id="messages"></div>
        <div class="input-group">
            <input type="text" id="userInput" placeholder="ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..." style="width: 60%;" />
            <button onclick="sendMessage()">ì „ì†¡</button>
            <select id="micSelect" style="padding: 5px; margin-left: 5px;"></select> <!-- ë§ˆì´í¬ ì„ íƒ ë©”ë‰´ -->
            <button id="voiceButton" onclick="toggleSpeechRecognition()">ğŸ¤ ìŒì„± ì¸ì‹</button>
            <button id="speakButton" onclick="toggleSpeechSynthesis()">ğŸ”Š ìŒì„± ì¶œë ¥</button>
            <button id="emotionButton" onclick="toggleEmotionRecognition()">ğŸ˜ƒ ê°ì • ì¸ì‹</button>
        </div>
        <div class="mic-visualizer">
            <div id="micBar" class="mic-visualizer-bar"></div> <!-- ìŒëŸ‰ ë§‰ëŒ€ë°” -->
        </div>
        <div class="emotion-display" id="emotionDisplay">ê°ì •: </div>
        <div style="position: relative; display: inline-block;">
            <video id="video" autoplay></video>
            <canvas id="canvasOverlay"></canvas>
        </div>
    </div>

    <script>
        // ìŒì„± ì¸ì‹ ë³€ìˆ˜
        let recognition;
        let recognizing = false;
        let speaking = false;
        let selectedMicId = ''; // ì„ íƒëœ ë§ˆì´í¬ ID
        const micSelect = document.getElementById('micSelect');
        const micBar = document.getElementById('micBar'); // ìŒëŸ‰ ë§‰ëŒ€ë°”

        // ì˜¤ë””ì˜¤ ì‹œê°í™” ë³€ìˆ˜
        let audioContext;
        let analyser;
        let micStream;

        // ìŒì„± ì¶œë ¥ ë³€ìˆ˜
        const synth = window.speechSynthesis;

        // ê°ì • ì¸ì‹ ë³€ìˆ˜
        const video = document.getElementById('video');
        const canvasOverlay = document.getElementById('canvasOverlay');
        const emotionDisplay = document.getElementById("emotionDisplay");
        const context = canvasOverlay.getContext('2d');
        let emotionRecognitionEnabled = false;  // ê°ì • ì¸ì‹ ìƒíƒœ ë³€ìˆ˜

        // ë²„íŠ¼ í™œì„±í™” ì‹œê°ì  í”¼ë“œë°±
        function toggleButtonActive(button) {
            button.classList.toggle('active');
        }

        // ê°ì • ì¸ì‹ í† ê¸€ í•¨ìˆ˜
        function toggleEmotionRecognition() {
            emotionRecognitionEnabled = !emotionRecognitionEnabled;
            toggleButtonActive(document.getElementById('emotionButton'));
            
            if (emotionRecognitionEnabled) {
                startEmotionRecognition();
            } else {
                stopEmotionRecognition();
            }
        }


        // ê°ì • ì¸ì‹ ì‹œì‘ í•¨ìˆ˜
        function startEmotionRecognition() {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.style.display = 'block';
                    canvasOverlay.style.display = 'block';
                    video.addEventListener('loadedmetadata', () => {
                        canvasOverlay.width = video.videoWidth;
                        canvasOverlay.height = video.videoHeight;
                    });
                })
                .catch(error => console.error("ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜:", error));
        }

        // ê°ì • ì¸ì‹ ì •ì§€ í•¨ìˆ˜
        function stopEmotionRecognition() {
            const stream = video.srcObject;
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop()); // ëª¨ë“  íŠ¸ë™ ì •ì§€
            }
            video.srcObject = null;
            video.style.display = 'none';
            canvasOverlay.style.display = 'none';
            emotionDisplay.innerText = "ê°ì •: ";  // ê°ì • ìƒíƒœ ì´ˆê¸°í™”
            context.clearRect(0, 0, canvasOverlay.width, canvasOverlay.height);  // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
        }

        // ì£¼ê¸°ì ìœ¼ë¡œ ì´ë¯¸ì§€ ìº¡ì²˜í•˜ì—¬ ê°ì • ë¶„ì„
        function captureImageAndSend() {
            if (!emotionRecognitionEnabled) return;  // ê°ì • ì¸ì‹ ë¹„í™œì„±í™” ìƒíƒœë©´ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ
            
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);

            canvas.toBlob(blob => {
                const formData = new FormData();
                formData.append('image', blob, 'capture.jpg');
                
                fetch('/analyze_emotion', {
                    method: 'POST',
                    body: formData
                })
                .then(response => response.json())
                .then(data => {
                    emotionDisplay.innerText = "ê°ì •: " + data.emotion;
                    
                    // ì–¼êµ´ ìœ„ì¹˜ ë°•ìŠ¤ ì„¤ì •
                    context.clearRect(0, 0, canvasOverlay.width, canvasOverlay.height);
                    if (data.region) {
                        const { x, y, w, h } = data.region;
                        context.strokeStyle = 'red';
                        context.lineWidth = 2;
                        context.strokeRect(x, y, w, h);
                    }
                })
                .catch(error => console.error("ê°ì • ë¶„ì„ ì˜¤ë¥˜:", error));
            }, 'image/jpeg');
        }

        // ì£¼ê¸°ì ìœ¼ë¡œ ê°ì • ë¶„ì„ ìˆ˜í–‰
        setInterval(captureImageAndSend, 5000);

        // í˜ì´ì§€ ë¡œë“œ ì‹œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        window.addEventListener('load', populateMicOptions);

        // ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ë‚˜ì—´ í•¨ìˆ˜
        async function populateMicOptions() {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioDevices = devices.filter(device => device.kind === 'audioinput');
            micSelect.innerHTML = ''; // ê¸°ì¡´ ì˜µì…˜ ì´ˆê¸°í™”
            audioDevices.forEach(device => {
                const option = document.createElement('option');
                option.value = device.deviceId;
                option.text = device.label || `Microphone ${micSelect.length + 1}`;
                micSelect.appendChild(option);
            });
        }

        // ë§ˆì´í¬ ìŒëŸ‰ ì‹œê°í™” ì‹œì‘
        async function startMicVisualizer() {
            selectedMicId = micSelect.value; // ì„ íƒëœ ë§ˆì´í¬ ID ì €ì¥

            if (micStream) {
                micStream.getTracks().forEach(track => track.stop()); // ì´ì „ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
            }

            micStream = await navigator.mediaDevices.getUserMedia({
                audio: { deviceId: selectedMicId ? { exact: selectedMicId } : undefined }
            });

            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256; // ì‘ì€ FFT í¬ê¸°
            }

            const source = audioContext.createMediaStreamSource(micStream);
            source.connect(analyser);

            visualizeMicVolume();
        }

        // ë§ˆì´í¬ ìŒëŸ‰ ì‹œê°í™” ì—…ë°ì´íŠ¸
        function visualizeMicVolume() {
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            function draw() {
                analyser.getByteFrequencyData(dataArray);
                const volume = Math.max(...dataArray) / 255; // 0.0 ~ 1.0 ì‚¬ì´ ê°’
                micBar.style.width = `${volume * 100}%`; // ë§‰ëŒ€ë°” í¬ê¸° ì—…ë°ì´íŠ¸
                requestAnimationFrame(draw); // ë°˜ë³µ í˜¸ì¶œ
            }
            draw();
        }
        
        // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
        async function initializeSpeechRecognition() {
            if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
                alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
                return;
            }

            try {
                selectedMicId = micSelect.value; // ì„ íƒëœ ë§ˆì´í¬ ID ì €ì¥

                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { deviceId: selectedMicId ? { exact: selectedMicId } : undefined }
                });

                recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                recognition.lang = 'ko-KR';
                recognition.interimResults = false;
                recognition.maxAlternatives = 1;

                recognition.onstart = () => {
                    console.log("ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...");
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    document.getElementById('userInput').value = transcript;
                    console.log("ì¸ì‹ëœ í…ìŠ¤íŠ¸:", transcript);
                    sendMessage();
                };

                recognition.onerror = (event) => {
                    console.error("ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", event.error);
                };

                recognition.onend = () => {
                    console.log("ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
                    if (recognizing) {
                        recognition.start();
                    }
                };

            } catch (error) {
                console.error("ìŒì„± ì¸ì‹ ì´ˆê¸°í™” ì˜¤ë¥˜:", error);
            }
        }

        // ìŒì„± ì¸ì‹ í† ê¸€
        function toggleSpeechRecognition() {
            if (!recognition) {
                initializeSpeechRecognition();
            }

            if (recognition) {
                if (recognizing) {
                    recognition.stop();
                    recognizing = false;
                    toggleButtonActive(document.getElementById('voiceButton'));
                } else {
                    recognition.start();
                    recognizing = true;
                    toggleButtonActive(document.getElementById('voiceButton'));
                    console.log("ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤");
                }
            }
        }

        // ìŒì„± ì¶œë ¥ í† ê¸€
        function toggleSpeechSynthesis() {
            speaking = !speaking;
            toggleButtonActive(document.getElementById('speakButton'));
        
            //if (!speaking && synth.speaking) {
            //  synth.cancel();

            // ìŒì„± ì¶œë ¥ í™œì„±í™” ì‹œ Safari í˜¸í™˜ì„± ê³ ë ¤
            if (speaking && 'speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance("ìŒì„± ì¶œë ¥ì´ ì‹œì‘ë©ë‹ˆë‹¤.");
                utterance.lang = 'ko-KR';
                utterance.volume = 0.3;  // ë³¼ë¥¨ ê°’ì„ 0.0 ~ 1.0 ì‚¬ì´ë¡œ ì„¤ì • (0.8 ì˜ˆì‹œ)
                synth.speak(utterance);
            } else {
                synth.cancel(); // ë¹„í™œì„±í™” ì‹œ ê¸°ì¡´ ìŒì„± ì¶œë ¥ì„ ì¤‘ì§€
            }
        }


        // í…ìŠ¤íŠ¸ ìŒì„± ì¶œë ¥
        function speakText(text) {
            if (speaking && 'speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'ko-KR';

                // ìŒì„± í•©ì„± ì‹œì‘ ì‹œ ìŒì„± ì¸ì‹ ì¤‘ì§€
                if (recognizing) {
                    recognition.stop();
                    recognizing = false;
                    toggleButtonActive(document.getElementById('voiceButton'));
                }

                // ìŒì„± í•©ì„± ì¢…ë£Œ í›„ ìŒì„± ì¸ì‹ ì¬ê°œ
                utterance.onend = () => {
                    console.log("ìŒì„± ì¶œë ¥ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
                    if (recognition && !recognizing) {
                        recognition.start();
                        recognizing = true;
                        toggleButtonActive(document.getElementById('voiceButton'));
                    }
                };

                synth.speak(utterance);
            }
        }

        // ë©”ì‹œì§€ ì „ì†¡
        function sendMessage() {
            const userMessage = document.getElementById('userInput').value;
            if (userMessage.trim() === '') return;

            const messagesDiv = document.getElementById('messages');
            const userMessageDiv = document.createElement('div');
            userMessageDiv.innerHTML = '<b>ì‚¬ìš©ì:</b> ' + userMessage;
            messagesDiv.appendChild(userMessageDiv);

            fetch('/get', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded'
                },
                body: 'msg=' + encodeURIComponent(userMessage)
            })
            .then(response => response.json())
            .then(data => {
                const botMessageDiv = document.createElement('div');
                //botMessageDiv.innerHTML = `<b>ë´‡:</b> ${data.command} <br> ${data.answer}`;
                botMessageDiv.innerHTML = `<b>ë´‡:</b> {command: ${data.command}}, <br> {answer: ${data.answer}}`;
                messagesDiv.appendChild(botMessageDiv);
                messagesDiv.scrollTop = messagesDiv.scrollHeight;

                // "answer" ë¶€ë¶„ë§Œ ìŒì„± ì¶œë ¥
                speakText(data.answer);
            });

            document.getElementById('userInput').value = '';
        }

        // "Enter" í‚¤ë¡œ ë©”ì‹œì§€ ë³´ë‚´ê¸°
        document.getElementById('userInput').addEventListener('keyup', function(event) {
            if (event.key === 'Enter') {
                sendMessage();
                event.preventDefault();
            }
        });
    </script>
</body>
</html>
